{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDXL Image Generator with LoRA & Refiner Support\n",
    "A memory-efficient Stable Diffusion XL image generator for Google Colab/Jupyter notebooks\n",
    "with 8-bit quantization, LoRA model support, and optional refiner enhancement.\n",
    "\n",
    "## Features\n",
    "- SDXL Base 1.0 with 8-bit quantization for low VRAM usage\n",
    "- Optional SDXL Refiner for enhanced details\n",
    "- LoRA model support for style customization\n",
    "- Gradio web interface with share link\n",
    "- Optimized for Google Colab free tier\n",
    "\n",
    "## Requirements\n",
    "- GPU with at least 12GB VRAM (T4 or better)\n",
    "- Python 3.8+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "Run this cell first to install all required dependencies. This will take 2-3 minutes on first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def check_gpu():\n",
    "    try:\n",
    "        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(\"‚úÖ GPU detected!\")\n",
    "            print(result.stdout.split('\\n')[8:11])\n",
    "        else:\n",
    "            print(\"‚ùå No GPU detected. This notebook requires a GPU.\")\n",
    "            sys.exit(1)\n",
    "    except:\n",
    "        print(\"‚ùå nvidia-smi not found. Please enable GPU in Runtime > Change runtime type\")\n",
    "        sys.exit(1)\n",
    "\n",
    "check_gpu()\n",
    "\n",
    "# Install dependencies\n",
    "print(\"\\nüì¶ Installing dependencies...\")\n",
    "!pip install -q --upgrade pip\n",
    "!pip cache purge -q\n",
    "\n",
    "# Install packages - let pip resolve torch version to avoid conflicts\n",
    "!pip install -q \\\n",
    "    gradio==4.44.1 \\\n",
    "    diffusers==0.29.1 \\\n",
    "    transformers==4.41.0 \\\n",
    "    accelerate==0.29.0 \\\n",
    "    huggingface_hub==0.25.0 \\\n",
    "    safetensors==0.4.2 \\\n",
    "    xformers \\\n",
    "    bitsandbytes==0.42.0 \\\n",
    "    websockets>=13.0 \\\n",
    "    pillow \\\n",
    "    tqdm\n",
    "\n",
    "# Verify torch installation\n",
    "import torch\n",
    "print(f\"\\n‚úÖ Torch version: {torch.__version__}\")\n",
    "\n",
    "print(\"‚úÖ Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports and Configuration\n",
    "Import required libraries and set up configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "from diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline\n",
    "from transformers import BitsAndBytesConfig\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Memory cleanup function\n",
    "def cleanup_memory():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"üîß PyTorch version: {torch.__version__}\")\n",
    "print(f\"üîß CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üîß GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üîß Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Loading\n",
    "Load SDXL base model with 8-bit quantization. This will download ~6.5GB on first run and take 3-5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüöÄ Loading SDXL base model...\")\n",
    "\n",
    "# Configure 8-bit quantization for memory efficiency\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    bnb_8bit_compute_dtype=torch.float16,\n",
    "    bnb_8bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# Load SDXL base pipeline\n",
    "try:\n",
    "    pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "        \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"balanced\",\n",
    "        quantization_config=bnb_config,\n",
    "        use_safetensors=True,\n",
    "        variant=\"fp16\"\n",
    "    )\n",
    "    \n",
    "    # Enable memory efficient attention\n",
    "    pipe.enable_xformers_memory_efficient_attention()\n",
    "    pipe.enable_vae_slicing()\n",
    "    pipe.enable_vae_tiling()\n",
    "    \n",
    "    print(\"‚úÖ SDXL base model loaded successfully!\")\n",
    "    cleanup_memory()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading model: {e}\")\n",
    "    raise\n",
    "\n",
    "# Refiner placeholder (loaded on demand)\n",
    "refiner = None\n",
    "\n",
    "def load_refiner():\n",
    "    \"\"\"Load SDXL refiner model on demand to save memory.\"\"\"\n",
    "    global refiner\n",
    "    if refiner is None:\n",
    "        print(\"üöÄ Loading SDXL refiner...\")\n",
    "        try:\n",
    "            refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
    "                \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
    "                torch_dtype=torch.float16,\n",
    "                device_map=\"balanced\",\n",
    "                quantization_config=bnb_config,\n",
    "                use_safetensors=True,\n",
    "                variant=\"fp16\"\n",
    "            )\n",
    "            refiner.enable_xformers_memory_efficient_attention()\n",
    "            refiner.enable_vae_slicing()\n",
    "            refiner.enable_vae_tiling()\n",
    "            print(\"‚úÖ SDXL refiner loaded successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading refiner: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image Generation Functions\n",
    "Core image generation logic with LoRA and refiner support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track loaded LoRA to avoid reloading\n",
    "current_lora_id = \"\"\n",
    "\n",
    "def generate_image(\n",
    "    prompt, \n",
    "    negative_prompt=\"\",\n",
    "    num_steps=30, \n",
    "    guidance_scale=7.5,\n",
    "    width=1024,\n",
    "    height=1024,\n",
    "    seed=-1,\n",
    "    use_refiner=False, \n",
    "    refiner_steps=10,\n",
    "    refiner_strength=0.3,\n",
    "    lora_model=\"\", \n",
    "    lora_scale=0.5,\n",
    "    advanced_mode=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate images using SDXL with optional LoRA and refiner.\n",
    "    \"\"\"\n",
    "    global current_lora_id\n",
    "    \n",
    "    try:\n",
    "        # Set random seed\n",
    "        generator = None\n",
    "        if seed != -1:\n",
    "            generator = torch.Generator(device=\"cuda\").manual_seed(seed)\n",
    "        \n",
    "        # Handle LoRA loading/unloading\n",
    "        if advanced_mode and lora_model:\n",
    "            if lora_model != current_lora_id:\n",
    "                # Unload previous LoRA\n",
    "                if current_lora_id:\n",
    "                    print(f\"üîÑ Unloading LoRA: {current_lora_id}\")\n",
    "                    pipe.unload_lora_weights()\n",
    "                    cleanup_memory()\n",
    "                \n",
    "                # Load new LoRA\n",
    "                try:\n",
    "                    print(f\"üì• Loading LoRA: {lora_model}\")\n",
    "                    pipe.load_lora_weights(lora_model)\n",
    "                    current_lora_id = lora_model\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è LoRA loading failed: {e}\")\n",
    "                    current_lora_id = \"\"\n",
    "            \n",
    "            # Set LoRA scale\n",
    "            if current_lora_id:\n",
    "                pipe.set_adapters([\"default\"], adapter_weights=[lora_scale])\n",
    "        \n",
    "        # Generate base image\n",
    "        print(f\"üé® Generating image...\")\n",
    "        result = pipe(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            num_inference_steps=int(num_steps),\n",
    "            guidance_scale=float(guidance_scale),\n",
    "            width=width,\n",
    "            height=height,\n",
    "            generator=generator\n",
    "        )\n",
    "        \n",
    "        image = result.images[0]\n",
    "        \n",
    "        # Apply refiner if requested\n",
    "        if advanced_mode and use_refiner:\n",
    "            load_refiner()\n",
    "            print(f\"‚ú® Applying refiner...\")\n",
    "            image = refiner(\n",
    "                prompt=prompt,\n",
    "                negative_prompt=negative_prompt,\n",
    "                image=image,\n",
    "                num_inference_steps=int(refiner_steps),\n",
    "                strength=float(refiner_strength),\n",
    "                generator=generator\n",
    "            ).images[0]\n",
    "        \n",
    "        cleanup_memory()\n",
    "        return image\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Generation error: {str(e)}\")\n",
    "        cleanup_memory()\n",
    "        # Return error placeholder\n",
    "        error_img = Image.new(\"RGB\", (512, 512), color=(255, 0, 0))\n",
    "        return error_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gradio Interface\n",
    "Create the web UI using Gradio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSS for better styling\n",
    "custom_css = \"\"\"\n",
    "    .container {max-width: 1200px; margin: auto; padding: 20px;}\n",
    "    .generate-btn {background: linear-gradient(90deg, #4CAF50 0%, #45a049 100%); color: white;}\n",
    "    .generate-btn:hover {background: linear-gradient(90deg, #45a049 0%, #4CAF50 100%);}\n",
    "\"\"\"\n",
    "\n",
    "# Build the interface\n",
    "with gr.Blocks(css=custom_css, title=\"SDXL Generator\") as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # üé® SDXL Image Generator\n",
    "    ### Generate stunning images with Stable Diffusion XL\n",
    "    \n",
    "    **Features:** 8-bit quantization for low VRAM ‚Ä¢ LoRA support ‚Ä¢ Optional refiner ‚Ä¢ Optimized for Colab\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        # Left column - Controls\n",
    "        with gr.Column(scale=1):\n",
    "            # Basic controls\n",
    "            with gr.Group():\n",
    "                gr.Markdown(\"### Basic Settings\")\n",
    "                prompt_input = gr.Textbox(\n",
    "                    lines=3,\n",
    "                    label=\"Prompt\",\n",
    "                    placeholder=\"Describe what you want to generate...\\nBe specific about style, lighting, and details.\",\n",
    "                    value=\"\"\n",
    "                )\n",
    "                \n",
    "                negative_prompt = gr.Textbox(\n",
    "                    lines=2,\n",
    "                    label=\"Negative Prompt\",\n",
    "                    placeholder=\"What to avoid: blurry, low quality, distorted...\",\n",
    "                    value=\"blurry, low quality, ugly, distorted\"\n",
    "                )\n",
    "                \n",
    "                with gr.Row():\n",
    "                    steps_slider = gr.Slider(\n",
    "                        minimum=10, maximum=50, value=25, step=1,\n",
    "                        label=\"Steps\", info=\"More steps = better quality but slower\"\n",
    "                    )\n",
    "                    guidance_slider = gr.Slider(\n",
    "                        minimum=1.0, maximum=20.0, value=7.5, step=0.5,\n",
    "                        label=\"Guidance Scale\", info=\"How closely to follow prompt\"\n",
    "                    )\n",
    "                \n",
    "                with gr.Row():\n",
    "                    width_slider = gr.Slider(\n",
    "                        minimum=512, maximum=2048, value=1024, step=64,\n",
    "                        label=\"Width\"\n",
    "                    )\n",
    "                    height_slider = gr.Slider(\n",
    "                        minimum=512, maximum=2048, value=1024, step=64,\n",
    "                        label=\"Height\"\n",
    "                    )\n",
    "                \n",
    "                seed_input = gr.Number(\n",
    "                    value=-1, label=\"Seed\", \n",
    "                    info=\"Use -1 for random, or specific number for reproducibility\"\n",
    "                )\n",
    "            \n",
    "            # Advanced settings\n",
    "            advanced_mode = gr.Checkbox(label=\"üîß Enable Advanced Mode\", value=False)\n",
    "            \n",
    "            with gr.Group(visible=False) as advanced_group:\n",
    "                gr.Markdown(\"### Advanced Settings\")\n",
    "                \n",
    "                # Refiner settings\n",
    "                with gr.Accordion(\"‚ú® Refiner Settings\", open=True):\n",
    "                    use_refiner = gr.Checkbox(label=\"Use Refiner\", value=False)\n",
    "                    refiner_steps = gr.Slider(\n",
    "                        minimum=5, maximum=30, value=10, step=1,\n",
    "                        label=\"Refiner Steps\"\n",
    "                    )\n",
    "                    refiner_strength = gr.Slider(\n",
    "                        minimum=0.1, maximum=0.5, value=0.3, step=0.05,\n",
    "                        label=\"Refiner Strength\", \n",
    "                        info=\"How much the refiner changes the image\"\n",
    "                    )\n",
    "                \n",
    "                # LoRA settings\n",
    "                with gr.Accordion(\"üé≠ LoRA Settings\", open=True):\n",
    "                    lora_model = gr.Textbox(\n",
    "                        label=\"LoRA Model ID\",\n",
    "                        placeholder=\"e.g., TheLastBen/Papercut_SDXL\",\n",
    "                        info=\"HuggingFace model ID for style LoRAs\"\n",
    "                    )\n",
    "                    lora_scale = gr.Slider(\n",
    "                        minimum=0.0, maximum=1.5, value=0.7, step=0.1,\n",
    "                        label=\"LoRA Weight\", \n",
    "                        info=\"Strength of LoRA influence\"\n",
    "                    )\n",
    "            \n",
    "            generate_btn = gr.Button(\"üöÄ Generate Image\", variant=\"primary\", elem_classes=\"generate-btn\")\n",
    "        \n",
    "        # Right column - Output\n",
    "        with gr.Column(scale=1):\n",
    "            output_image = gr.Image(\n",
    "                label=\"Generated Image\",\n",
    "                type=\"pil\",\n",
    "                interactive=False\n",
    "            )\n",
    "            \n",
    "            with gr.Row():\n",
    "                gr.Markdown(\"\"\"\n",
    "                **Tips:**\n",
    "                - Start with 25-30 steps for good quality\n",
    "                - Use negative prompts to avoid unwanted elements\n",
    "                - LoRA models can dramatically change the style\n",
    "                - Refiner adds details but increases generation time\n",
    "                \"\"\")\n",
    "    \n",
    "    # Examples\n",
    "    with gr.Row():\n",
    "        gr.Examples(\n",
    "            examples=[\n",
    "                [\n",
    "                    \"A majestic lion in African savanna at golden hour, photorealistic, detailed fur, 8k quality\",\n",
    "                    \"blurry, cartoon, anime, low quality\",\n",
    "                    25, 7.5, 1024, 1024, 42\n",
    "                ],\n",
    "                [\n",
    "                    \"Fantasy castle floating in clouds, magical atmosphere, detailed architecture, trending on artstation\",\n",
    "                    \"modern, contemporary, cars, people\",\n",
    "                    30, 8.0, 1024, 1024, 123\n",
    "                ],\n",
    "                [\n",
    "                    \"Cyberpunk street scene, neon lights, rain, detailed, blade runner style, cinematic\",\n",
    "                    \"daylight, sunny, medieval, ancient\",\n",
    "                    30, 7.0, 1344, 768, 456\n",
    "                ]\n",
    "            ],\n",
    "            inputs=[prompt_input, negative_prompt, steps_slider, guidance_slider, \n",
    "                   width_slider, height_slider, seed_input],\n",
    "            label=\"Example Prompts\"\n",
    "        )\n",
    "    \n",
    "    # Event handlers\n",
    "    advanced_mode.change(\n",
    "        fn=lambda x: gr.update(visible=x),\n",
    "        inputs=advanced_mode,\n",
    "        outputs=advanced_group\n",
    "    )\n",
    "    \n",
    "    generate_btn.click(\n",
    "        fn=generate_image,\n",
    "        inputs=[\n",
    "            prompt_input, negative_prompt,\n",
    "            steps_slider, guidance_slider,\n",
    "            width_slider, height_slider, seed_input,\n",
    "            use_refiner, refiner_steps, refiner_strength,\n",
    "            lora_model, lora_scale,\n",
    "            advanced_mode\n",
    "        ],\n",
    "        outputs=output_image\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Launch the App\n",
    "Launch the Gradio interface with a public share link. The share link expires after 72 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüåê Launching Gradio interface...\")\n",
    "print(\"üìù Note: Share links expire after 72 hours\")\n",
    "print(\"üí° Tip: For faster generation, reduce steps or image size\\n\")\n",
    "\n",
    "# Launch with share link\n",
    "demo.launch(\n",
    "    share=True,\n",
    "    debug=False,\n",
    "    show_error=True,\n",
    "    server_name=\"0.0.0.0\",\n",
    "    server_port=7860,\n",
    "    quiet=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Popular LoRA Models\n",
    "\n",
    "- `TheLastBen/Papercut_SDXL` - Paper cut art style\n",
    "- `artificialguybr/LogoRedmond-LogoLoraForSDXL` - Logo design\n",
    "- `KappaNeuro/studio-ghibli-style-sdxl` - Studio Ghibli style\n",
    "- `alvdansen/frosting_lane_redux_sdxl` - Vintage photography\n",
    "\n",
    "## ‚ö†Ô∏è Troubleshooting\n",
    "\n",
    "- **Out of Memory**: Reduce image size or use fewer steps\n",
    "- **LoRA Not Loading**: Check the model ID is correct on HuggingFace\n",
    "- **Slow Generation**: Normal for SDXL; 30-60 seconds per image on T4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
