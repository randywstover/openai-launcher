{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŽ¨ Stable Diffusion XL Image Generator\n",
        "Generate high-quality images with Stable Diffusion XL (SDXL) 1.0 using Colabâ€™s free GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â”€â”€â”€ Setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 1) Clear pip cache\n",
        "!pip cache purge\n",
        "\n",
        "# 2) Install all compatible versions at once:\n",
        "!pip install -q \\\n",
        "    diffusers==0.29.1 \\\n",
        "    transformers>=4.41.0,<5.0.0 \\\n",
        "    accelerate==0.29.0 \\\n",
        "    huggingface_hub>=0.25.0 \\\n",
        "    safetensors==0.4.2 \\\n",
        "    gradio==4.29.0 \\\n",
        "    torch \\\n",
        "    bitsandbytes \\\n",
        "    xformers \\\n",
        "    websockets>=13.0,<15.0dev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline\n",
        "from transformers import BitsAndBytesConfig\n",
        "import gradio as gr\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Loading Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8-bit quantization config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_8bit=True,\n",
        "    bnb_8bit_compute_dtype=torch.float16,\n",
        ")\n",
        "pipe = None\n",
        "refiner = None\n",
        "\n",
        "def load_base_model():\n",
        "    global pipe\n",
        "    if pipe is None:\n",
        "        pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "            \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\",\n",
        "            quantization_config=bnb_config,\n",
        "        )\n",
        "        try:\n",
        "            pipe.enable_xformers_memory_efficient_attention()\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "def load_refiner_model():\n",
        "    global refiner\n",
        "    if refiner is None:\n",
        "        refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
        "            \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\",\n",
        "            quantization_config=bnb_config,\n",
        "        )\n",
        "        try:\n",
        "            refiner.enable_xformers_memory_efficient_attention()\n",
        "        except:\n",
        "            pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_image(\n",
        "    prompt:str,\n",
        "    negative_prompt:str=\"\",\n",
        "    num_steps:int=30,\n",
        "    guidance_scale:float=7.5,\n",
        "    use_refiner:bool=False,\n",
        "    refiner_steps:int=10,\n",
        "    lora_model:str=\"\",\n",
        "    lora_scale:float=0.5,\n",
        "    advanced_mode:bool=False\n",
        "):\n",
        "    load_base_model()\n",
        "    kwargs = {}\n",
        "    if advanced_mode and lora_model.strip():\n",
        "        try:\n",
        "            pipe.unet.load_attn_procs(lora_model)\n",
        "            kwargs={\"scale\":lora_scale}\n",
        "        except:\n",
        "            return Image.new(\"RGB\",(1024,1024),\"black\")\n",
        "\n",
        "    img = pipe(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_inference_steps=num_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        cross_attention_kwargs=kwargs\n",
        "    ).images[0]\n",
        "\n",
        "    if advanced_mode and use_refiner:\n",
        "        load_refiner_model()\n",
        "        img = refiner(\n",
        "            prompt=prompt,\n",
        "            negative_prompt=negative_prompt,\n",
        "            num_inference_steps=refiner_steps,\n",
        "            image=img\n",
        "        ).images[0]\n",
        "\n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradio Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# ðŸŽ¨ SDXL Image Generator\")\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=2):\n",
        "            prompt = gr.Textbox(label=\"Prompt\", lines=2)\n",
        "            neg    = gr.Textbox(label=\"Negative Prompt\", lines=1)\n",
        "            steps  = gr.Slider(1,100,value=30,label=\"Steps\")\n",
        "            scale  = gr.Slider(1.0,20.0,value=7.5,label=\"Guidance\")\n",
        "            adv    = gr.Checkbox(label=\"Advanced Mode\")\n",
        "            ref    = gr.Checkbox(label=\"Use Refiner\")\n",
        "            rsteps = gr.Slider(1,50,value=10,label=\"Refiner Steps\")\n",
        "            lmodel = gr.Textbox(label=\"LoRA ID\")\n",
        "            lscale = gr.Slider(0.0,2.0,value=0.5,label=\"LoRA Scale\")\n",
        "            adv.change(lambda v: gr.update(visible=v),adv,[ref,rsteps,lmodel,lscale])\n",
        "            btn = gr.Button(\"Generate\")\n",
        "        with gr.Column(scale=2):\n",
        "            out = gr.Image(type=\"pil\")\n",
        "\n",
        "    btn.click(\n",
        "        fn=generate_image,\n",
        "        inputs=[prompt,neg,steps,scale,ref,rsteps,lmodel,lscale,adv],\n",
        "        outputs=out\n",
        "    )\n",
        "\n",
        "    demo.launch(\n",
        "        share=True,\n",
        "        server_name=\"0.0.0.0\",\n",
        "        server_port=0,\n",
        "        prevent_thread_lock=True\n",
        "    )\n"
      ]
    }
  ],
  "metadata": {
    "accelerator":"GPU",
    "colab":{"name":"stable-diffusion-xl.ipynb","provenance":[]},
    "kernelspec":{"display_name":"Python 3","name":"python3"},
    "language_info":{"name":"python"}
  },
  "nbformat":4,
  "nbformat_minor":0
}
