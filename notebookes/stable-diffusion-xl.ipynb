{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¨ Stable Diffusion XL Image Generator\n",
    "\n",
    "Generate high-quality images with Stable Diffusion XL (SDXL) using Colab's free GPU. No installation or API key required.\n",
    "\n",
    "## Model Information\n",
    "This notebook uses SDXL 1.0, offering:\n",
    "- Higher resolution outputs (1024Ã—1024)\n",
    "- Better composition and coherence\n",
    "- Improved prompt understanding\n",
    "- Advanced features like LoRA support\n",
    "\n",
    "## Features\n",
    "- State-of-the-art image generation\n",
    "- Simple interface with prompt input\n",
    "- Multiple generation settings\n",
    "- Negative prompts support\n",
    "- Optional SDXL refiner for enhanced details\n",
    "- Support for custom LoRA models\n",
    "\n",
    "## Advanced Features\n",
    "### Using the SDXL Refiner\n",
    "The refiner model enhances image details and quality. Enable it for better results at the cost of longer generation time.\n",
    "\n",
    "### Using Custom LoRA Models\n",
    "You can use custom LoRA models from Hugging Face to modify the generation style:\n",
    "1. Find a LoRA model on Hugging Face (e.g., 'ostris/super-realistic-xl')\n",
    "2. Enter the model ID in the LoRA field\n",
    "3. Adjust the LoRA scale (0.0-1.0) to control the effect strength\n",
    "\n",
    "## Setup\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q diffusers==0.24.0 transformers accelerate gradio torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base model\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    torch_dtype=torch.float16,\n",
    "    variant=\"fp16\",\n",
    "    use_safetensors=True\n",
    ")\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "# Refiner model (load only when needed)\n",
    "refiner = None\n",
    "\n",
    "def load_refiner():\n",
    "    global refiner\n",
    "    if refiner is None:\n",
    "        refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
    "            \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
    "            torch_dtype=torch.float16,\n",
    "            variant=\"fp16\",\n",
    "            use_safetensors=True\n",
    "        )\n",
    "        refiner.to(\"cuda\")\n",
    "\n",
    "# Enable memory efficient attention\n",
    "pipe.enable_xformers_memory_efficient_attention()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(prompt, negative_prompt=\"\", num_steps=30, guidance_scale=7.5, \n",
    "                  use_refiner=False, refiner_steps=10, lora_model=\"\", lora_scale=0.5,\n",
    "                  advanced_mode=False):\n",
    "    # Load LoRA if specified\n",
    "    if advanced_mode and lora_model:\n",
    "        try:\n",
    "            pipe.load_lora_weights(lora_model)\n",
    "            pipe.fuse_lora(lora_scale)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading LoRA model: {e}\")\n",
    "    \n",
    "    # Generate base image\n",
    "    image = pipe(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        num_inference_steps=num_steps,\n",
    "        guidance_scale=guidance_scale,\n",
    "    ).images[0]\n",
    "    \n",
    "    # Apply refiner if enabled\n",
    "    if advanced_mode and use_refiner:\n",
    "        load_refiner()\n",
    "        image = refiner(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            num_inference_steps=refiner_steps,\n",
    "            image=image\n",
    "        ).images[0]\n",
    "    \n",
    "    # Unfuse LoRA if it was used\n",
    "    if advanced_mode and lora_model:\n",
    "        pipe.unfuse_lora()\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as interface:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # Stable Diffusion XL Image Generator\n",
    "        Generate high-quality images from text descriptions using SDXL.\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=2):\n",
    "            prompt = gr.Textbox(label=\"Prompt\", placeholder=\"Enter your image description here...\")\n",
    "            negative_prompt = gr.Textbox(label=\"Negative Prompt\", placeholder=\"What you don't want in the image...\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                num_steps = gr.Slider(minimum=1, maximum=50, value=30, step=1, label=\"Number of Steps\")\n",
    "                guidance_scale = gr.Slider(minimum=1, maximum=20, value=7.5, step=0.5, label=\"Guidance Scale\")\n",
    "            \n",
    "            advanced_mode = gr.Checkbox(label=\"Advanced Mode\", value=False)\n",
    "            \n",
    "            with gr.Column(visible=False) as advanced_options:\n",
    "                use_refiner = gr.Checkbox(label=\"Use Refiner\", value=False)\n",
    "                refiner_steps = gr.Slider(minimum=1, maximum=50, value=10, step=1, label=\"Refiner Steps\")\n",
    "                lora_model = gr.Textbox(label=\"LoRA Model ID\", placeholder=\"e.g., ostris/super-realistic-xl\")\n",
    "                lora_scale = gr.Slider(minimum=0, maximum=1, value=0.5, step=0.1, label=\"LoRA Scale\")\n",
    "            \n",
    "            advanced_mode.change(lambda x: gr.Column(visible=x), advanced_mode, advanced_options)\n",
    "        \n",
    "        with gr.Column(scale=2):\n",
    "            output = gr.Image(label=\"Generated Image\")\n",
    "    \n",
    "    gr.Examples([\n",
    "        [\"A majestic lion in the savanna at sunset, highly detailed, professional photography\", \n",
    "         \"blurry, low quality\", 30, 7.5, False, 10, \"\", 0.5, False],\n",
    "        [\"A futuristic cityscape with flying cars and neon lights, cyberpunk style\", \n",
    "         \"grainy, ugly, distorted\", 30, 7.5, True, 10, \"\", 0.5, True]\n",
    "    ], [prompt, negative_prompt, num_steps, guidance_scale, use_refiner, refiner_steps, \n",
    "        lora_model, lora_scale, advanced_mode])\n",
    "    \n",
    "    inputs = [prompt, negative_prompt, num_steps, guidance_scale, use_refiner, \n",
    "              refiner_steps, lora_model, lora_scale, advanced_mode]\n",
    "    \n",
    "    gr.Interface(fn=generate_image, inputs=inputs, outputs=output)\n",
    "\n",
    "interface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Stable Diffusion XL",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
