{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üé® Stable Diffusion XL Image Generator\n",
        "Generate high-quality images with Stable Diffusion XL (SDXL) 1.0 using Colab‚Äôs free GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ‚îÄ‚îÄ‚îÄ Setup ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 1) Clear old pip cache\n",
        "!pip cache purge\n",
        "\n",
        "# 2) Install compatible versions in one shot:\n",
        "!pip install -q \\\n",
        "    diffusers==0.29.1 \\\n",
        "    transformers>=4.41.0,<5.0.0 \\\n",
        "    accelerate==0.29.0 \\\n",
        "    huggingface_hub>=0.25.0 \\\n",
        "    safetensors==0.4.2 \\\n",
        "    gradio==4.29.0 \\\n",
        "    torch \\\n",
        "    bitsandbytes \\\n",
        "    xformers \\\n",
        "    websockets>=13.0,<15.0dev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline\n",
        "from transformers import BitsAndBytesConfig\n",
        "import gradio as gr\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Loading Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8-bit quantization config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_8bit=True,\n",
        "    bnb_8bit_compute_dtype=torch.float16,\n",
        ")\n",
        "pipe = None      # base pipeline\n",
        "refiner = None   # img2img refiner pipeline\n",
        "\n",
        "def load_base_model():\n",
        "    global pipe\n",
        "    if pipe is None:\n",
        "        print(\"Loading SDXL base model...\")\n",
        "        pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "            \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\",\n",
        "            quantization_config=bnb_config,\n",
        "        )\n",
        "        try:\n",
        "            pipe.enable_xformers_memory_efficient_attention()\n",
        "            print(\"‚úÖ xFormers attention enabled\")\n",
        "        except Exception as e:\n",
        "            print(\"‚ö†Ô∏è xFormers unavailable:\", e)\n",
        "\n",
        "def load_refiner_model():\n",
        "    global refiner\n",
        "    if refiner is None:\n",
        "        print(\"Loading SDXL refiner model...\")\n",
        "        refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
        "            \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\",\n",
        "            quantization_config=bnb_config,\n",
        "        )\n",
        "        try:\n",
        "            refiner.enable_xformers_memory_efficient_attention()\n",
        "            print(\"‚úÖ xFormers attention for refiner enabled\")\n",
        "        except Exception as e:\n",
        "            print(\"‚ö†Ô∏è xFormers unavailable for refiner:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_image(\n",
        "    prompt: str,\n",
        "    negative_prompt: str = \"\",\n",
        "    num_steps: int = 30,\n",
        "    guidance_scale: float = 7.5,\n",
        "    use_refiner: bool = False,\n",
        "    refiner_steps: int = 10,\n",
        "    lora_model: str = \"\",\n",
        "    lora_scale: float = 0.5,\n",
        "    advanced_mode: bool = False,\n",
        ") -> Image.Image:\n",
        "    try:\n",
        "        load_base_model()\n",
        "\n",
        "        # LoRA loading\n",
        "        cross_attention_kwargs = {}\n",
        "        if advanced_mode and lora_model.strip():\n",
        "            try:\n",
        "                pipe.unet.load_attn_procs(lora_model)\n",
        "                cross_attention_kwargs = {\"scale\": lora_scale}\n",
        "                print(f\"‚úÖ LoRA loaded: {lora_model} @ {lora_scale}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå LoRA error: {e}\")\n",
        "                return Image.new(\"RGB\", (1024, 1024), color=\"black\")\n",
        "\n",
        "        # Base generation\n",
        "        img = pipe(\n",
        "            prompt=prompt,\n",
        "            negative_prompt=negative_prompt,\n",
        "            num_inference_steps=num_steps,\n",
        "            guidance_scale=guidance_scale,\n",
        "            cross_attention_kwargs=cross_attention_kwargs,\n",
        "        ).images[0]\n",
        "\n",
        "        # Refiner\n",
        "        if advanced_mode and use_refiner:\n",
        "            load_refiner_model()\n",
        "            img = refiner(\n",
        "                prompt=prompt,\n",
        "                negative_prompt=negative_prompt,\n",
        "                num_inference_steps=refiner_steps,\n",
        "                image=img,\n",
        "            ).images[0]\n",
        "\n",
        "        return img\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Generation error: {e}\")\n",
        "        return Image.new(\"RGB\", (1024, 1024), color=\"black\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradio Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\n",
        "        \"# üé® Stable Diffusion XL\\nGenerate high-quality images from text with SDXL 1.0.\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=2):\n",
        "            prompt = gr.Textbox(\n",
        "                label=\"Prompt\",\n",
        "                placeholder=\"A futuristic cityscape at dusk\",\n",
        "                lines=2,\n",
        "            )\n",
        "            negative_prompt = gr.Textbox(\n",
        "                label=\"Negative Prompt\",\n",
        "                placeholder=\"blurry, low quality\",\n",
        "                lines=1,\n",
        "            )\n",
        "\n",
        "            num_steps = gr.Slider(1, 100, value=30, label=\"Inference Steps\")\n",
        "            guidance_scale = gr.Slider(1.0, 20.0, value=7.5, label=\"Guidance Scale\")\n",
        "\n",
        "            advanced = gr.Checkbox(label=\"Advanced Mode\", value=False)\n",
        "            use_refiner = gr.Checkbox(label=\"Use Refiner\", value=False)\n",
        "            refiner_steps = gr.Slider(1, 50, value=10, label=\"Refiner Steps\")\n",
        "            lora_model = gr.Textbox(label=\"LoRA Model ID\", placeholder=\"HF repo path or local folder\")\n",
        "            lora_scale = gr.Slider(0.0, 2.0, value=0.5, label=\"LoRA Scale\")\n",
        "\n",
        "            advanced.change(\n",
        "                fn=lambda t: gr.update(visible=t),\n",
        "                inputs=advanced,\n",
        "                outputs=[use_refiner, refiner_steps, lora_model, lora_scale],\n",
        "            )\n",
        "\n",
        "            btn = gr.Button(\"Generate Image\")\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            output = gr.Image(label=\"Generated Image\", type=\"pil\")\n",
        "\n",
        "    btn.click(\n",
        "        fn=generate_image,\n",
        "        inputs=[\n",
        "            prompt, negative_prompt, num_steps,\n",
        "            guidance_scale, use_refiner, refiner_steps,\n",
        "            lora_model, lora_scale, advanced,\n",
        "        ],\n",
        "        outputs=output,\n",
        "    )\n",
        "\n",
        "demo.launch(share=True)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "stable-diffusion-xl.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
