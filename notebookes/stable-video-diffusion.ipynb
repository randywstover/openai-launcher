{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¬ Stable Video Diffusion\n",
    "\n",
    "Generate high-quality videos from text descriptions using Stability AI's Stable Video Diffusion model. This notebook runs in Colab's free tier and requires no API key.\n",
    "\n",
    "## Model Information\n",
    "This notebook supports both SVD and SVD-XT models:\n",
    "\n",
    "- **SVD (Default)**: Original model, good for most use cases\n",
    "  - 14 frames at 1024x576 resolution\n",
    "  - Consistent motion and quality\n",
    "  - Faster generation time\n",
    "\n",
    "- **SVD-XT**: Extended version with improvements\n",
    "  - Up to 25 frames at 1024x576\n",
    "  - Better motion consistency\n",
    "  - Improved visual quality\n",
    "  - Support for longer sequences\n",
    "\n",
    "## Features\n",
    "- Text-to-video generation\n",
    "- Multiple video styles\n",
    "- Adjustable generation parameters\n",
    "- Frame interpolation for smooth motion\n",
    "- Support for both SVD and SVD-XT models\n",
    "\n",
    "## Setup\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q diffusers transformers accelerate torch gradio moviepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableVideoDiffusionPipeline\n",
    "from diffusers.utils import export_to_video\n",
    "import gradio as gr\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available models\n",
    "MODELS = {\n",
    "    \"SVD\": \"stabilityai/stable-video-diffusion-img2vid\",\n",
    "    \"SVD-XT\": \"stabilityai/stable-video-diffusion-img2vid-xt\"\n",
    "}\n",
    "\n",
    "def load_model(model_name=\"SVD\"):\n",
    "    pipe = StableVideoDiffusionPipeline.from_pretrained(\n",
    "        MODELS[model_name],\n",
    "        torch_dtype=torch.float16,\n",
    "        variant=\"fp16\"\n",
    "    )\n",
    "    pipe.to(\"cuda\")\n",
    "    \n",
    "    # Enable memory efficient features\n",
    "    pipe.enable_model_cpu_offload()\n",
    "    pipe.enable_vae_slicing()\n",
    "    \n",
    "    return pipe\n",
    "\n",
    "# Initialize with default model\n",
    "pipe = load_model()\n",
    "\n",
    "print(f\"Model loaded on: {'GPU' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_video(prompt, model_name=\"SVD\", num_frames=14, fps=8, \n",
    "                  motion_bucket_id=127, noise_aug_strength=0.1,\n",
    "                  min_guidance_scale=1.0, max_guidance_scale=3.0,\n",
    "                  seed=-1):\n",
    "    global pipe\n",
    "    \n",
    "    # Load selected model if different from current\n",
    "    if model_name != getattr(pipe, \"_model_name\", \"SVD\"):\n",
    "        pipe = load_model(model_name)\n",
    "        pipe._model_name = model_name\n",
    "    \n",
    "    # Set random seed if provided\n",
    "    if seed != -1:\n",
    "        torch.manual_seed(seed)\n",
    "    \n",
    "    # Adjust frames based on model\n",
    "    if model_name == \"SVD\" and num_frames > 14:\n",
    "        num_frames = 14\n",
    "    elif model_name == \"SVD-XT\" and num_frames > 25:\n",
    "        num_frames = 25\n",
    "    \n",
    "    # Generate video frames\n",
    "    frames = pipe(\n",
    "        prompt,\n",
    "        num_inference_steps=25,\n",
    "        num_frames=num_frames,\n",
    "        motion_bucket_id=motion_bucket_id,\n",
    "        noise_aug_strength=noise_aug_strength,\n",
    "        min_guidance_scale=min_guidance_scale,\n",
    "        max_guidance_scale=max_guidance_scale\n",
    "    ).frames[0]\n",
    "    \n",
    "    # Save video\n",
    "    output_path = \"output.mp4\"\n",
    "    export_to_video(frames, output_path, fps=fps)\n",
    "    \n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as interface:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # Stable Video Diffusion\n",
    "        Generate videos from text descriptions using Stability AI's Stable Video Diffusion model.\n",
    "        Choose between SVD (original) and SVD-XT (extended) models.\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=2):\n",
    "            prompt = gr.Textbox(\n",
    "                label=\"Prompt\",\n",
    "                placeholder=\"Describe the video you want to generate...\",\n",
    "                lines=3\n",
    "            )\n",
    "            \n",
    "            model_choice = gr.Radio(\n",
    "                choices=[\"SVD\", \"SVD-XT\"],\n",
    "                value=\"SVD\",\n",
    "                label=\"Model\",\n",
    "                info=\"SVD-XT supports longer sequences but may be slower\"\n",
    "            )\n",
    "            \n",
    "            with gr.Row():\n",
    "                num_frames = gr.Slider(\n",
    "                    minimum=8,\n",
    "                    maximum=25,\n",
    "                    value=14,\n",
    "                    step=1,\n",
    "                    label=\"Number of Frames\",\n",
    "                    info=\"SVD: max 14, SVD-XT: max 25\"\n",
    "                )\n",
    "                fps = gr.Slider(\n",
    "                    minimum=4,\n",
    "                    maximum=30,\n",
    "                    value=8,\n",
    "                    step=1,\n",
    "                    label=\"FPS\",\n",
    "                    info=\"Frames per second\"\n",
    "                )\n",
    "            \n",
    "            with gr.Accordion(\"Advanced Settings\", open=False):\n",
    "                motion_bucket_id = gr.Slider(\n",
    "                    minimum=1,\n",
    "                    maximum=255,\n",
    "                    value=127,\n",
    "                    step=1,\n",
    "                    label=\"Motion Strength\",\n",
    "                    info=\"Higher values create more motion\"\n",
    "                )\n",
    "                noise_aug_strength = gr.Slider(\n",
    "                    minimum=0.0,\n",
    "                    maximum=1.0,\n",
    "                    value=0.1,\n",
    "                    step=0.1,\n",
    "                    label=\"Noise Strength\",\n",
    "                    info=\"Higher values create more varied motion\"\n",
    "                )\n",
    "                with gr.Row():\n",
    "                    min_guidance = gr.Slider(\n",
    "                        minimum=1.0,\n",
    "                        maximum=10.0,\n",
    "                        value=1.0,\n",
    "                        step=0.5,\n",
    "                        label=\"Min Guidance Scale\"\n",
    "                    )\n",
    "                    max_guidance = gr.Slider(\n",
    "                        minimum=1.0,\n",
    "                        maximum=10.0,\n",
    "                        value=3.0,\n",
    "                        step=0.5,\n",
    "                        label=\"Max Guidance Scale\"\n",
    "                    )\n",
    "                seed = gr.Number(\n",
    "                    value=-1,\n",
    "                    label=\"Random Seed\",\n",
    "                    info=\"Set to -1 for random results\"\n",
    "                )\n",
    "        \n",
    "        with gr.Column(scale=2):\n",
    "            output = gr.Video(label=\"Generated Video\")\n",
    "    \n",
    "    gr.Examples([\n",
    "        [\"A serene lake at sunset with gentle ripples on the water\", \"SVD\", 14, 8, 127, 0.1, 1.0, 3.0, -1],\n",
    "        [\"A blooming flower opening its petals in timelapse\", \"SVD-XT\", 25, 12, 200, 0.2, 1.0, 3.0, -1],\n",
    "        [\"A space shuttle launching into the sky with smoke trails\", \"SVD-XT\", 20, 15, 255, 0.3, 1.0, 3.0, -1]\n",
    "    ], [prompt, model_choice, num_frames, fps, motion_bucket_id, noise_aug_strength, \n",
    "        min_guidance, max_guidance, seed])\n",
    "    \n",
    "    inputs = [prompt, model_choice, num_frames, fps, motion_bucket_id, \n",
    "              noise_aug_strength, min_guidance, max_guidance, seed]\n",
    "    \n",
    "    gr.Interface(fn=generate_video, inputs=inputs, outputs=output)\n",
    "\n",
    "interface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Stable Video Diffusion",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
